% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/xkern.R
\name{xkern}
\alias{xkern}
\title{X-learner implemented via kernel ridge regression (with a Gaussian kernel)}
\usage{
xkern(x, w, y, k_folds = NULL, b_range = 10^(seq(-3, 3, 0.5)),
  lambda_range = 10^(seq(-3, 3, 0.5)), mu1_hat = NULL,
  mu0_hat = NULL, p_hat = NULL)
}
\arguments{
\item{x}{the input features}

\item{w}{the treatment variable (0 or 1)}

\item{y}{the observed response (real valued)}

\item{k_folds}{number of folds for cross-fitting}

\item{b_range}{the range of Gaussian kernel bandwidths for cross validation}

\item{lambda_range}{the range of ridge regression penalty factor for cross validation}

\item{mu1_hat}{pre-computed estimates on E[Y|X,W=1] corresponding to the input x. xkern will compute it internally if not provided.}

\item{mu0_hat}{pre-computed estimates on E[Y|X,W=0] corresponding to the input x. xkern will compute it internally if not provided.}

\item{p_hat}{user-supplied estimate for E[W|X]. xkern will compute it internally if not provided.}
}
\description{
X-learner as proposed by Kunzel, Sekhon, Bickel, and Yu (2017), implemented via kernel ridge regression (with a Gaussian kernel)
}
\examples{
\dontrun{
n = 100; p = 10

x = matrix(rnorm(n*p), n, p)
w = rbinom(n, 1, 0.5)
y = pmax(x[,1], 0) * w + x[,2] + pmin(x[,3], 0) + rnorm(n)

xkern_fit = xkern(x, w, y)
xkern_est = predict(xkern_fit, x)
}

}
